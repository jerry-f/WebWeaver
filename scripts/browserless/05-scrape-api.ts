/**
 * Browserless Scrape API æµ‹è¯•
 *
 * ã€åŠŸèƒ½è¯´æ˜ã€‘
 * ä½¿ç”¨ Stealth æ¨¡å¼é€šè¿‡ CSS é€‰æ‹©å™¨æå–é¡µé¢å†…å®¹
 * è‡ªåŠ¨ç»•è¿‡åçˆ¬è™«æ£€æµ‹
 *
 * ã€è¿è¡Œæ–¹å¼ã€‘
 * npx tsx scripts/browserless/05-scrape-api.ts
 */

import { BrowserlessClient } from './utils/browserless-client'

const client = new BrowserlessClient()

/**
 * æµ‹è¯• 1: æå–é¡µé¢æ ‡é¢˜å’Œæ®µè½
 */
async function testBasicScrape() {
  console.log('\nğŸ” æµ‹è¯• 1: æå–é¡µé¢æ ‡é¢˜å’Œæ®µè½')
  console.log('-'.repeat(40))

  const url = 'https://example.com'
  console.log(`ç›®æ ‡ URL: ${url}`)
  console.log(`é€‰æ‹©å™¨: h1, p`)

  const startTime = Date.now()
  const results = await client.scrape(url, {
    selectors: ['h1', 'p'],
    waitUntil: 'domcontentloaded',
    timeout: 10000
  })
  const duration = Date.now() - startTime

  console.log(`\nâœ… æå–æˆåŠŸ (${duration}ms)\n`)

  for (const item of results) {
    console.log(`é€‰æ‹©å™¨: ${item.selector}`)
    console.log(`  åŒ¹é…æ•°é‡: ${item.results.length}`)
    for (const result of item.results.slice(0, 3)) {
      const text = result.text.substring(0, 50)
      console.log(`  - "${text}${result.text.length > 50 ? '...' : ''}"`)
    }
    console.log('')
  }
}

/**
 * æµ‹è¯• 2: æŠ“å–æœ‰åçˆ¬è™«ç½‘ç«™ï¼ˆStealth æ¨¡å¼ï¼‰
 */
async function testAntiScrapingSite() {
  console.log('\nğŸ” æµ‹è¯• 2: æŠ“å–æœ‰åçˆ¬è™«çš„ç½‘ç«™ (Stealth æ¨¡å¼)')
  console.log('-'.repeat(40))

  const url = 'https://news.ycombinator.com'
  console.log(`ç›®æ ‡ URL: ${url}`)
  console.log(`é€‰æ‹©å™¨: .titleline > a`)
  console.log(`è¯´æ˜: æ­¤ç½‘ç«™ä¼šæ£€æµ‹è‡ªåŠ¨åŒ–å·¥å…·ï¼Œä½¿ç”¨ Stealth æ¨¡å¼ç»•è¿‡`)

  const startTime = Date.now()
  const results = await client.scrape(url, {
    selectors: ['.titleline > a'],
    waitUntil: 'domcontentloaded',
    timeout: 20000
  })
  const duration = Date.now() - startTime

  const titles = results[0]?.results || []

  console.log(`\nâœ… æå–æˆåŠŸ (${duration}ms)`)
  console.log(`   æ–‡ç« æ•°é‡: ${titles.length}\n`)

  console.log('å‰ 10 ç¯‡æ–‡ç« :')
  for (const [index, item] of titles.slice(0, 10).entries()) {
    const title = item.text.substring(0, 50)
    const href = item.attributes.href || ''
    console.log(`  ${(index + 1).toString().padStart(2)}. ${title}`)
    console.log(`      ${href.substring(0, 60)}${href.length > 60 ? '...' : ''}`)
  }
}

/**
 * æµ‹è¯• 3: æå–å¤šç§å…ƒç´ 
 */
async function testMultipleSelectors() {
  console.log('\nğŸ” æµ‹è¯• 3: æå–å¤šç§å…ƒç´ ')
  console.log('-'.repeat(40))

  const url = 'https://example.com'
  console.log(`ç›®æ ‡ URL: ${url}`)

  const results = await client.scrape(url, {
    selectors: ['title', 'h1', 'a'],
    waitUntil: 'domcontentloaded',
    timeout: 10000
  })

  console.log(`\nâœ… æå–æˆåŠŸ\n`)

  for (const item of results) {
    console.log(`é€‰æ‹©å™¨: ${item.selector}`)
    console.log(`  åŒ¹é…æ•°é‡: ${item.results.length}`)

    if (item.selector === 'title') {
      console.log(`  æ ‡é¢˜: ${item.results[0]?.text || '(æ— )'}`)
    } else if (item.selector === 'a') {
      console.log(`  é“¾æ¥:`)
      for (const link of item.results.slice(0, 3)) {
        console.log(`    - ${link.text}: ${link.attributes.href || '(æ— )'}`)
      }
    } else {
      for (const result of item.results.slice(0, 2)) {
        console.log(`  - ${result.text.substring(0, 40)}`)
      }
    }
    console.log('')
  }
}

/**
 * ä¸»å‡½æ•°
 */
async function main() {
  console.log('='.repeat(60))
  console.log('Browserless Scrape API æµ‹è¯• (Stealth æ¨¡å¼)')
  console.log('='.repeat(60))

  try {
    await testBasicScrape()
    await testAntiScrapingSite()
    await testMultipleSelectors()

    console.log('\n' + '='.repeat(60))
    console.log('âœ… æ‰€æœ‰æµ‹è¯•å®Œæˆ')
    console.log('='.repeat(60))
  } catch (error) {
    console.error('\nâŒ æµ‹è¯•å¤±è´¥:', error)
    process.exit(1)
  }
}

main()
